---
title: 广告平台扩容重构
---

## 1 版本修订记录

| 日期 | 内容 | 作者 |
|:-|:-|:-|
|2017-06-29|首发|诸葛亮|


# 2. 重构目标

- 提升CS系统容量，通过无限水平扩容，理论上支持无上限的点击量
- 实时统计数据
- 提升稳定性
- 提升服务器利用率、控制服务器成本

# 2.1 重构关键任务点

- 定时任务分离
- 点击等数据存储，由缓存转移到MongoDB等服务
- 使用新的逻辑进行统计
- 数据实时性
- 规划重构阶段，最小范围调整，上线验证
- 服务迁移到阿里，采用小型廉价机器部署方案

# 3. 系统方案设计
## 3.1 框架设计
### 3.1.1 原有结构和依赖关系
![image](/assets/images/cs_1.png)

说明：

- adt-web为用户的SAAS控制台模块，用户在系统中编辑广告等配置信息时，会把信息同步到Memcached缓存中
- adt-data为接收点击和转化请求的模块，收到点击后，会读取Memcached中配置信息，解释请求，再丢到Redis队列中
- adt-handle，包括：点击&转化请求消费，数据从Redis往MySQL迁移以及一些定时统计的任务，依赖MySQL和Redis
- python为遗留项目，提供了一些代adt-web调用的报表数据接口

问题：

- 对Memcached依赖严重，且各自依赖数据结构，adt-web调整极有可能影响到adt-data和dat-handle服务的正常
- 遗留python，现在团队规模小，有问题时调整困难
- adt-handle功能臃肿，无法通过水平扩容，快速提升系统容量
- 广告监测，使用Redis作为存储媒介，成本高；
- 明细数据存储和统计，使用MySQL，效率低。

### 3.1.2 新框架和依赖设计

![image](/assets/images/cs_2.png)

说明：

- 蓝色是新增或拆分出来的模块
- adt-data保持不变
- adt-handle拆分为adt-handle和adt-data-task。adt-handle仅保留点击和转化数据消费相关的功能
- adt-data-task，包括从adt-handle中拆分出来的定时统计相关的功能
- 引入队列，具体的中间件，见关键技术选型-队列
- 新增配置服务，屏蔽广告监测数据侧对缓存的绝对依赖
- 新增adt-data-server，提供统计数据的接口给adt-web
- 新增MongoDB用于存储点击和转化明细数据

## 3.2 关键技术选型

- 队列
  - ActiveMq （舍弃）
    根据PAD使用情况，问题比较多，如：缺乏注册中心，分布式下每新增一台MQ服务，都必须调整配置文件，将新的生产和消费服务指向它，运维成本高

  - Kafka （推荐）
    拥有注册中心，消息处理能力强

  - RocketMQ
    待定

  - Redis
    可使用list等数据类型实现队列效果，但还是非标准的队列中间件。且数据堆积时，完全占用内容，提高了服务器的成本

- 点击&转化明细数据存储
  - Redis
    效率高，存储和读取的速度都非常快，但成本高，且不可靠

  - MongoDB（推荐）
    存储效率高，读取的速度也十分的快，同时本身支持水平扩容。自带的MapReduce处理，可加快报表统计。

  - MongoDB云服务
    运维投入低，成本。

  - HBase（待定）
    不了解细节

  - Mysql（舍弃）
    存储量低，效率低，数据量大时，检索慢

## 3.3 关键功能设计

### 3.3.1 点击处理
![image](/assets/images/cs_3.png)

### 3.3.2 转化处理

与原有逻辑基本一致，但直接从MongoDB中取点击进行匹配。同时消息传递和通知直接基于队列，不再依赖Redis。

![image](/assets/images/cs_4.png)

### 3.3.3 转化限制处理

转化限制的处理是，将待转化限制广告的转化，临时存储起来，经过一定时间后，再取出所有的缓冲转化，按照转化限制的规则标识转化限制和不转化限制，再进行转化处理，最后到“已处理转化中”，如下图所示：
![image](/assets/images/cs_5.png)
调整：
- 原有定时监测转化限制缓冲到期，在handle处理中，转移到adt-data-task模块；
- 判定检测到期后，直接往队列中发送满足条件的key，替换为原有将key写入另外一Redis集合中的处理

### 3.3.4 数据实时

整体的逻辑是，用缓存实时计数，得到瞬时值，定期将数据，进行统计，落地到MySQL统计报表中。

缓存的计数，按小时进行统计

- 方案A
缓存+Mongo统计。在处理点击和转化时，使用缓存累加点击和转化。间隔单位时间，如10分钟，启动任务，在Mongo中基于明细数据，进行统计，得到结果，存储到MySQL中，并重置缓存的值。
界面显示的值是MySQL+缓存中的值。

- 方案B
完全基于缓存进行统计，在处理点击和转化时，进行实时的叠加，每10分钟，将数据同步到数据库中。

## 3.4 数据结构设计

### 3.4.1 MySQL 

MySQL表结构与现有保持一致

### 3.4.2 MongoDB
- 点击 clicks
  - 主键id: tid
  - 分片索引：offerid, affid, id
  - 其它索引：sdate
  - 字段：点击相关信息所有的字段

- 转化 converions
  - 主键：tid
  - 索引：offerid, affid, sdate
  - 字段：点击&转化，相关信息所有字段

### 3.4.3 实时统计缓存数据结构

待补充

# 4 项目实施阶段

- 第一阶段
  - 拆分模块，实现水平扩容
  - 基于现有配置依赖缓存的方式开发
  - 将明细数据落地到MongoDB
  - 基于MongoDB进行报表统计
  - 项目上线时，迁移回阿里，纯阿里海外服务器部署

- 第二阶段
  - 待1.2.2完整开发完时，一并发布
  - 数据实时
  - 去缓存依赖，依赖服务化
  - 考虑国内海外系统整合

## 4.1 实施方案

### 4.1.1 第一阶段迁移至阿里